Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,1.4177178,-1.7039212,57.62573099415204,-2.399999990489553,-2.399999990489553,1.4939208,0.25378668,0.00027046577,1.0
20000,1.4265273,0.27785408,25.88679245283019,1.9374663560899763,1.9374663560899763,2.0104802,0.24452512,0.00020988597,1.0
30000,1.4297307,1.086443,17.558441558441558,3.6580706266807272,3.6580706266807272,2.0676062,0.24785082,0.00014982917,1.0
40000,1.4227479,1.1005491,15.9830220713073,4.279117348099504,4.279117348099504,1.9569412,0.2484308,9.01086e-05,1.0
50000,1.4228438,1.1343653,16.69734513274336,4.496283354221192,4.496283354221192,1.8046008,0.24133976,2.9993633e-05,1.0
